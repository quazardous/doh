---
title: "Create convergence algorithm and consensus detection system"
status: open
priority: high
size: M
parallel: false
depends_on: [001, 002, 003, 004]
created: 2025-08-31T00:34:44Z
updated: 2025-08-31T00:34:44Z
epic: prd-committee
tags: [convergence-algorithm, consensus-detection, mathematical-analysis, decision-system]
---

# Create Convergence Algorithm and Consensus Detection System

## Summary

Implement the mathematical convergence algorithm that analyzes agent ratings and feedback to determine whether the committee has reached consensus or requires CTO escalation. This system processes the rating matrix, detects patterns of agreement/disagreement, and triggers appropriate next steps in the workflow.

## Acceptance Criteria

- [ ] Algorithm processes complete rating matrix from all 4 agents
- [ ] Calculates multiple convergence metrics: variance, standard deviation, outlier detection
- [ ] Implements configurable consensus thresholds with reasonable defaults
- [ ] Detects irreconcilable differences that require escalation
- [ ] Provides detailed analysis explaining convergence decision
- [ ] Handles edge cases: missing ratings, agent conflicts, partial responses
- [ ] Generates actionable recommendations for next steps
- [ ] Integration with session orchestrator for automatic decision-making

## Technical Requirements

### Core Algorithm Components
- **Variance Analysis**: Calculate rating variance per PRD section across agents
- **Outlier Detection**: Identify agents with consistently divergent ratings
- **Pattern Recognition**: Detect systematic disagreements between agent pairs
- **Trend Analysis**: Compare Round 1 vs Round 2 rating improvements

### Convergence Metrics
- **Threshold-Based**: Configurable variance thresholds (default: σ² < 1.5)
- **Percentage Agreement**: Minimum % of ratings within ±1 point (default: 75%)
- **Improvement Rate**: Round 2 variance reduction compared to Round 1
- **Critical Section Analysis**: Higher standards for key PRD sections (requirements, success criteria)

### Decision Logic
- **Consensus Achieved**: Low variance + high agreement + adequate improvement
- **Needs Iteration**: Moderate variance but showing improvement trend
- **Escalation Required**: High variance + no improvement + systematic conflicts
- **Partial Consensus**: Some sections converged, others requiring focused iteration

### Mathematical Specifications

#### Rating Matrix Analysis
```
Rating Matrix: R[agent][section] = {score, feedback}
Variance per section: Var(section) = σ²(R[*][section])
Global variance: GlobalVar = mean(Var(all_sections))
Improvement: Δ = Round1_Var - Round2_Var
```

#### Consensus Thresholds
- **Strong Consensus**: Variance < 1.0 AND 90%+ within ±1 point
- **Weak Consensus**: Variance < 2.0 AND 75%+ within ±1 point  
- **No Consensus**: Variance > 3.0 OR <50% within ±2 points
- **Degrading**: Round 2 variance > Round 1 variance

## Architecture Design

### Key Classes/Components
- `ConvergenceAnalyzer`: Main algorithm implementation
- `RatingMatrixProcessor`: Handles rating data structures and calculations
- `ThresholdManager`: Configurable consensus criteria
- `ConflictDetector`: Identifies systematic agent disagreements
- `RecommendationEngine`: Generates next-step guidance

### Integration Points
- **Session Orchestrator**: Automatic convergence checking after Round 2
- **CTO Agent**: Escalation trigger with detailed conflict analysis
- **Rating Collection**: Direct input from rating aggregation system
- **Decision Logger**: Complete audit trail of convergence decisions

## Advanced Features

### Agent Expertise Weighting
- Optional weighting system based on domain relevance
- DevOps agent ratings weighted higher for security/infrastructure sections
- UX agent ratings prioritized for user experience sections
- Configurable weights with equal weighting as default

### Conflict Pattern Analysis
- Detect recurring agent pair conflicts (e.g., UX vs DevOps on security)
- Identify sections that consistently cause disagreement
- Generate insights about committee dynamics for CTO analysis

### Adaptive Thresholds
- Learn from successful past sessions to adjust thresholds
- Account for project complexity in threshold selection
- Different standards for different PRD section types

## Edge Case Handling

### Missing or Invalid Data
- Handle missing agent ratings gracefully (exclude from calculations)
- Validate rating ranges and format before processing
- Detect and flag suspicious patterns (all 10s, identical ratings)
- Graceful degradation when <3 agents provide ratings

### Boundary Conditions
- Single-section PRDs: Modified convergence criteria
- Large PRDs (>10 sections): Sectional convergence analysis
- Agent dropout: Recalculate thresholds for remaining participants
- Perfect initial consensus: Skip Round 2 optimization

### Mathematical Edge Cases
- Zero variance scenarios: Additional validation checks
- Outlier agents: Robust statistics using median-based measures
- Tied ratings: Use qualitative feedback as tiebreaker
- Non-normal distributions: Alternative convergence measures

## Performance Requirements

- Process complete rating matrix within 2 seconds
- Support analysis of up to 20 PRD sections simultaneously
- Handle rating matrices with missing data efficiently
- Generate human-readable analysis summary within 5 seconds

## Configuration Management

### Tunable Parameters
```yaml
convergence:
  variance_threshold: 1.5          # Maximum variance for consensus
  agreement_percentage: 75         # Minimum % within ±1 point
  improvement_required: 0.2        # Minimum Round2 improvement
  critical_sections: ['requirements', 'success-criteria']
  escalation_threshold: 3.0        # Automatic CTO escalation
```

### Section-Specific Thresholds
- Critical sections (requirements, success criteria): Stricter thresholds
- Descriptive sections (overview, background): Relaxed thresholds
- Technical sections: DevOps/Lead Dev weighted higher
- User sections: UX/PO weighted higher

## Definition of Done

- Algorithm correctly identifies consensus vs escalation scenarios
- All mathematical calculations are accurate and well-tested
- Configuration system allows threshold tuning without code changes
- Edge cases are handled gracefully with appropriate fallbacks
- Performance meets sub-2-second processing requirements
- Integration with orchestrator enables automatic decision-making
- Comprehensive test suite covers all convergence scenarios
- Detailed logging enables debugging of algorithm decisions
- Documentation includes mathematical specifications and examples

## Implementation Notes

- Start with basic variance calculation, then add advanced features
- Use robust statistical methods that handle outliers appropriately
- Implement extensive logging for algorithm debugging and tuning
- Consider using established mathematical libraries for statistical calculations
- Design for easy threshold adjustment based on real-world performance
- Include detailed explanation generation for human review of decisions